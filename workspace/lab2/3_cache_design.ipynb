{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Part 3: Optimize Matrix Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goal: Minimize the energy and the area of caches\n",
    "\n",
    "In this part, we will design both the loop nest for matrix multiplication and the caches, to minimize the energy and the area of caches while correctly computing matrix multiplication. \n",
    "\n",
    "#### Matrix Multiplication Problem\n",
    "\n",
    "$$\n",
    "C_{m,n} = \\sum_k A_{m,k} \\times B_{k,n}\n",
    "$$\n",
    "\n",
    "where A is a $M\\times K$ matrix and B is a $K\\times N$ matrix. The matrix dimensions for our problem are $M=64, K=256, N=64$. You can write your own loop nest with any loop orders and tiling strategies that produce a correct result. \n",
    "\n",
    "#### Constraints on Cache Designs\n",
    "\n",
    "You can use any number of different caches (each with a __minimum size of 64 words__). You can have a hierarchy of caches, or multiple small caches, or a single large cache as you like. However the hard constraint on cache design is on the total area and energy of all caches you use:\n",
    "\n",
    "- Total Area: $20000 \\mu m^2$  \n",
    "- Total Energy: $1 m\\text{J}$\n",
    "\n",
    "You are not allowed to use a register for storing partial sums for this question. Thus, for each accumulate operation (```z[m][n] += a[m][k] * b[k][n]```), you must have one read and one write. The purpose of this question is to explore changing the addressing, cache sizes and tiling strategy. There are multiple possible solutions to achieve a full score. \n",
    "\n",
    "Please do not modify the setup code (such as ```z = z_MN.getRoot()```) nor perform your own matrix multiplication using numpy arrays. You are allowed to do this for debugging purposes, but for the final answer please utilize the setup we provide.\n",
    "\n",
    "#### Important Notes about Energy and Area\n",
    "Note the following facts about area.\n",
    "- Larger caches use more area.\n",
    "- Set-associative caches use more area than direct-mapped caches for the same total capacity due to overheads.\n",
    "\n",
    "Note the following facts about energy.\n",
    "- Here, we measure the total energy: the sum of cache and off-chip memory energies.\n",
    "- Off-chip memory reads and writes cost more energy than cache reads and writes.\n",
    "- A single read/write of a larger cache costs more energy than a read/write of a smaller cache.\n",
    "- A single read/write of a set-associative cache costs more energy than direct-mapped cache.\n",
    "\n",
    "#### Grading\n",
    "\n",
    "First, clearly explain your assumptions and loop nest details in the cell below. Also, make sure you explain assumptions for your memory layout (e.g., row-major or column-major) and cache designs. You can write a pseudo-code to explain your loop ordering and tiling strategies. Please also explain at which part of the loop nest you are expecting memory access (load and store). \n",
    "\n",
    "Second, make sure you correctly write `getAddress` function that will be used to compute memory address. This function should reflect your cache design.\n",
    "\n",
    "Third, report your total cache area and energy. Grading will be based on these metrics with maximum score of 10 for the total area, and 10 for the total energy:\n",
    "\n",
    "| Score | Area ($\\mu m^2$) | Energy ($m\\text{J}$) |\n",
    "| ---   | ----             | ----                 |\n",
    "| + 10  | < 12000          |  < 0.65              |\n",
    "| + 8   | 12000 ~ 14000    |  0.65 ~ 0.75         |\n",
    "| + 6   | 14000 ~ 16000    |  0.75 ~ 0.85         |\n",
    "| + 4   | 16000 ~ 18000    |  0.85 ~ 0.95         |\n",
    "| + 2   | 18000 ~ 20000    |  0.95 ~ 1.0          |\n",
    "\n",
    "Lastly, breakdown the total energy for each cache you used, and analyze which operation consumes the most energy. Is there any method to improve that operation? You do not need to implement any codes, but please conceptually explain what modifications can be made to caches to reduce energy further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4253262e864a15b70accde94cf186e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='style', options=('tree', 'uncompressed', 'tree+uncompressed'), val…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f846f42173d4a339ce374659c542c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Run all cells below', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run boilerplate code to set up environment\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "from loaders import *\n",
    "\n",
    "from cache import Cache, CacheAssoc\n",
    "\n",
    "%run ./prelude.py --style=uncompressed --animation=none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "density = [1.0]\n",
    "seed = 10\n",
    "\n",
    "enable_log = False\n",
    "\n",
    "def set_params(**kwargs):\n",
    "    global enable_log\n",
    "    \n",
    "    for variable, value in kwargs.items():\n",
    "        globals()[variable] = value\n",
    "\n",
    "    enable_log = (kwargs[\"log\"] == 'enable')\n",
    "\n",
    "\n",
    "def logger(arg):\n",
    "    if enable_log:\n",
    "        print(arg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Input Tensors\n",
    "\n",
    "Given shapes selected above the below codeblock creates and displays the filter weights (**f**) and input activations (**i**) and a reference output (**o_verify**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 64\n",
    "K = 256\n",
    "N = 64\n",
    "\n",
    "a_MK_raw = []\n",
    "for m in range(M):\n",
    "    a_MK_raw.append([random.randint(1, 9) for i in range(K)])\n",
    "                 \n",
    "b_KN_raw = []\n",
    "for k in range(K):\n",
    "    b_KN_raw.append([random.randint(1, 9) for i in range(N)])\n",
    "\n",
    "a_MK = Tensor.fromUncompressed([\"M\", \"K\"], a_MK_raw)\n",
    "b_KN = Tensor.fromUncompressed([\"K\", \"N\"], b_KN_raw)\n",
    "\n",
    "a_MK.setName(\"A_MK\").setColor(\"blue\")\n",
    "b_KN.setName(\"B_KN\").setColor(\"green\")\n",
    "\n",
    "# print(\"Input A\")\n",
    "# displayTensor(a_MK)\n",
    "                    \n",
    "# print(\"Input B\")\n",
    "# displayTensor(b_KN)\n",
    "\n",
    "z_verify = None\n",
    "\n",
    "def create_z():\n",
    "    \"\"\"\n",
    "    Create a fully populated z tensor\n",
    "    \"\"\"\n",
    "    z = Tensor(rank_ids=[\"M\", \"N\"], default='')\n",
    "    z.setName(\"Z\")\n",
    "    z.setMutable(True)\n",
    "\n",
    "    z_m = z.getRoot()\n",
    "    #\n",
    "    # Hack to fill in all the entries in z\n",
    "    # This allows us to pretend the tensor is dense\n",
    "    #\n",
    "    n_fiber = Fiber(coords=range(N), initial=1)\n",
    "    m_fiber = Fiber(coords=range(M), initial=1)\n",
    "\n",
    "    for m, (z_n, _) in z_m << m_fiber:\n",
    "        for n, (z_ref, _) in z_n << n_fiber:\n",
    "            z_ref <<= 0\n",
    "            \n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get ground truth for the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Multiply\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 64/64 [00:21<00:00,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Matrix Multiply\")\n",
    "\n",
    "z_MN = create_z()\n",
    "\n",
    "# print(\"Output - before\")\n",
    "# displayTensor(z_MN)\n",
    "\n",
    "z = z_MN.getRoot()\n",
    "a = a_MK.getRoot()\n",
    "b = b_KN.getRoot()\n",
    "\n",
    "# Progress bar since this takes a while\n",
    "pbar = tqdm.tqdm(desc='Progress', total=M)\n",
    "\n",
    "# canvas = createCanvas(a_MK, b_KN, z_MN)\n",
    "for m in range(M):\n",
    "    pbar.update(1)\n",
    "    a_tile = [ (m, kt) for kt in range(K)]\n",
    "    for n in range(N):\n",
    "        logger(f\"Processing Z({m},{n}) = {z[m][n]}\")\n",
    "        b_tile = [ (kt, n) for kt in range(K)]\n",
    "        z_tile = (m, n)\n",
    "        for k in range(K):\n",
    "            logger(f\"Processing A({m},{k}) = {a[m][k].payload}\")\n",
    "            logger(f\"Processing B({k},{n}) = {b[k][n].payload}\")\n",
    "            \n",
    "            z[m][n] += a[m][k] * b[k][n]\n",
    "            # addActivity(canvas, a_tile, b_tile, z_tile, worker=\"W\")\n",
    "            # addFrame(canvas, (m,k), (k,n), (m,n))\n",
    "print('Done!')  \n",
    "pbar.close()\n",
    "\n",
    "# print(\"Output - after\")\n",
    "# displayTensor(z)\n",
    "\n",
    "# displayCanvas(canvas)\n",
    "\n",
    "if z_verify is None:\n",
    "    z_verify = deepcopy(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 9 \n",
    "\n",
    "Modify caches and loop nest below for your design. Run the cache profiler, and report the total area and energy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report: Design Strategy\n",
    "1) Pseudo-code for my loopnest choice:\n",
    "~~~\n",
    "for k1 in range(K1=16):\n",
    "    for m1 in range(M1=8):\n",
    "\t# A_tile changes each step of this for loop iteration (when m1 or k1 changes)\n",
    "\t# A_tile reads brand new set of (M0, K0)= (8, 16) sized tile\n",
    "\n",
    "        for n1 in range(N1=8):\n",
    "\t        - B_tile changes each step of this for loop iteration with size of (K0, N0) = (16, 8)\n",
    "            - tile moves in N-direction reading a brand-new set of tile\n",
    "\n",
    "            - C_tile changes each step of this for loop iteration with size of (M0, N0) = (8, 8)\n",
    "            - tile moves in N-direction reading a brand-new set of tile\n",
    "\n",
    "            for m0 in range(M0=8):\n",
    "                for n0 in range(N0=8):\n",
    "                    for k0 in range(K0=16):\n",
    "                        # compulsory cache misses can appear but after one cycle data (tiles) are reused\n",
    "                        # compulsory reads: read A_tile, B_tile, C_tile as defined above.\n",
    "                        # c += a * b operation performed in sequence (for C, read and write-through)\n",
    "~~~\n",
    "I assumed that for each A, B, C tile with size of (M0, K0), (K0, N0), and (M0, N0) respectively, the entire tile will fit into each cache without address conflicts. Normally, since default flattened addressing would easily cause address conflicts, I've created a very specialized address mapping that avoids conflict misses without using set associative cache to save area:\n",
    "1. For B, I added transpose option for getAddress such that B is shape (N, K) and sweep through K dimension becomes row-major order. To exploit this, I've made words_per_line for each cache to exactly be the 'tile width', or the length of consecutive reads for the lowest looping dimension. This makes subsequent reads of the same line within the tile be cached.\n",
    "2. Normal mapping causes problem when the \"subsequent line\" of the tile is read. Since the width of the tensor is a multiple of the number of lines in cache, next line will cause conflict misses. To avoid this, I used a very specific raster pattern address mapping, where the next line within the tile to read will exactly be adjacent to the previous line in the address space. This prevents conflict misses completely while being a 1-to-1 address mapping and hence implementable. In real-world scenarios, this wouldn't be desirable due to highly inflexible design.\n",
    "3. To decide looping order, since cache A and B is larger than C, I prioritized making the loopnest stationary for larger tensors (A or B, A chosen for here) while B and C tiles are looped faster.\n",
    "   \n",
    "#### Q) Improve Energy Consumption?\n",
    "\n",
    "Memory Access (both read and write) is most energy-demanding. In this end, Tensor C's memory write (1048576 operations) consume around 0.538mJ, or ~95% of the total energy. This number cannot be reduced if the current write-through policy is kept. We can change cache C to use write-back policy, in which partial sums are written back only if it is being evicted from the cache, which will dramatically reduce the total energy consumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your Code: Utility function for addressing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify this function if necessary (e.g., different memory addressing)\n",
    "\n",
    "def getAddress(tensor, x, y, width = 16, transpose=False):\n",
    "    row, col = tensor.getShape()\n",
    "    height = row if not transpose else col\n",
    "    if transpose:\n",
    "        x, y= y, x\n",
    "\n",
    "    return (height*width)*(y//width)+(y%width)+width*x\n",
    "    \n",
    "    #if transpose:\n",
    "    #    return  (y*tensor.getShape()[0]+x)\n",
    "    #return (x*tensor.getShape()[1]+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your Code: Caches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use direct-mapped caches or set-associative caches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your caches; minimum size is log_size=6\n",
    "# You can use any number of separate caches, as far as they meet area and energy constraints\n",
    "\n",
    "cache_a = Cache(log_size=7, words_per_line=16)\n",
    "cache_b = Cache(log_size=7, words_per_line=16)\n",
    "cache_c = Cache(log_size=6, words_per_line=8)\n",
    "\n",
    "# List all caches you are using\n",
    "caches = [cache_a, cache_b, cache_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your Code: Tiling and Loop Nest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Multiply\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 1024/1024 [04:22<00:00,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "-------Cache A--------\n",
      "Cache Statistics:\n",
      "cache rd: 1047552\n",
      "cache wr: 0\n",
      "mem rd: 1024\n",
      "mem wr: 0\n",
      "-------Cache B--------\n",
      "Cache Statistics:\n",
      "cache rd: 1040384\n",
      "cache wr: 0\n",
      "mem rd: 8192\n",
      "mem wr: 0\n",
      "-------Cache C--------\n",
      "Cache Statistics:\n",
      "cache rd: 1040384\n",
      "cache wr: 73728\n",
      "mem rd: 8192\n",
      "mem wr: 1048576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Tiling Size: Modify this to change tiling\n",
    "\n",
    "# M = M1 x M0\n",
    "# K = K1 x K0\n",
    "# N = N1 x N0\n",
    "\n",
    "M1 = 8\n",
    "M0 = 8\n",
    "K1 = 16\n",
    "K0 = 16\n",
    "N1 = 8\n",
    "N0 = 8\n",
    "\n",
    "print(\"Matrix Multiply\")\n",
    "\n",
    "z_MN = create_z()\n",
    "\n",
    "# print(\"Output - before\")\n",
    "# displayTensor(z_MN)\n",
    "\n",
    "z = z_MN.getRoot()\n",
    "a = a_MK.getRoot()\n",
    "b = b_KN.getRoot()\n",
    "\n",
    "# canvas = createCanvas(a_MK, b_KN, z_MN)\n",
    "\n",
    "# Progress bar since this takes a while\n",
    "pbar = tqdm.tqdm(desc='Progress', total=K1*M1*N1)\n",
    "\n",
    "# Loop Nest: Modify this to alter the for loop orders\n",
    "for k1 in range(K1):\n",
    "    for m1 in range(M1):\n",
    "        for n1 in range(N1):\n",
    "            pbar.update(1)\n",
    "            \n",
    "            a_tile = [ (m1*M0+mt, k1*K0+kt) for mt in range(M0)for kt in range(K0)]\n",
    "            b_tile = [ (k1*K0+kt, n1*N0+nt) for kt in range(K0)for nt in range(N0)]\n",
    "            z_tile = [ (m1*M0+mt, n1*N0+nt) for mt in range(M0)for nt in range(N0)]\n",
    "\n",
    "            for m0 in range(M0):\n",
    "                for n0 in range(N0):\n",
    "                    for k0 in range(K0):\n",
    "\n",
    "                        m = m1*M0+m0\n",
    "                        n = n1*N0+n0\n",
    "                        k = k1*K0+k0\n",
    "\n",
    "                        logger(f\"Processing A({m},{k}) = {a[m][k].payload}\")\n",
    "                        logger(f\"Processing B({k},{n}) = {b[k][n].payload}\")\n",
    "                        logger(f\"Processing Z({m},{n}) = {z[m][n]}\")\n",
    "\n",
    "                        cache_c.load(getAddress(z, m, n, 8))\n",
    "                        cache_a.load(getAddress(a, m, k, 16))\n",
    "                        cache_b.load(getAddress(b, k, n, 16, True))\n",
    "\n",
    "                        z[m][n] += a[m][k] * b[k][n]\n",
    "\n",
    "                        # addActivity(canvas, a_tile, b_tile, z_tile, worker=\"W\")\n",
    "                        # addFrame(canvas, (m,k), (k,n), (m,n))\n",
    "\n",
    "                        cache_c.store(getAddress(z, m, n))\n",
    "print('Done!')\n",
    "pbar.close()\n",
    "# print(\"Output - after\")\n",
    "# displayTensor(z)\n",
    "\n",
    "# displayCanvas(canvas)\n",
    "\n",
    "if z_verify is None:\n",
    "    print(\"Result not verified\")\n",
    "else:\n",
    "    assert z == z_verify\n",
    "\n",
    "# Print cache statistics\n",
    "print(\"-------Cache A--------\")\n",
    "cache_a.print_stats()\n",
    "print(\"-------Cache B--------\")\n",
    "cache_b.print_stats()\n",
    "print(\"-------Cache C--------\")\n",
    "cache_c.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Area / Energy Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache 1 Energy: 0.0068 mj, Area: 4767.25 um^2\n",
      "Cache 2 Energy: 0.0105 mj, Area: 4767.25 um^2\n",
      "Cache 3 Energy: 0.5432 mj, Area: 1685.26 um^2\n",
      "Total Energy: 0.5606 mj, Area: 11219.76 um^2\n",
      "3.1.1: \n",
      "\tTrue\n",
      "3.1.1: \n",
      "\tTrue\n",
      "3.1.1: \n",
      "\tTrue\n",
      "3.1.1: \n",
      "\tTrue\n",
      "3.1.1: \n",
      "\tTrue\n",
      "3.1.2: \n",
      "\tTrue\n",
      "3.1.2: \n",
      "\tTrue\n",
      "3.1.2: \n",
      "\tTrue\n",
      "3.1.2: \n",
      "\tTrue\n",
      "3.1.2: \n",
      "\tTrue\n"
     ]
    }
   ],
   "source": [
    "# You do not need to change any of this part.\n",
    "from cache_profiler import CacheProfiler\n",
    "\n",
    "res_list = []\n",
    "for cache in caches:\n",
    "    profiler = CacheProfiler(cache)\n",
    "    res = profiler.profile(cache.stats)\n",
    "    res_list.append(res)\n",
    "\n",
    "total_energy = 0\n",
    "total_area = 0\n",
    "for i, res in enumerate(res_list):\n",
    "    print(f\"Cache {i+1} Energy: {res['energy'] / 1e9 :.4f} mj, Area: {res['area'] :.2f} um^2\")\n",
    "    total_energy += res['energy']\n",
    "    total_area += res['area']\n",
    "\n",
    "total_energy /= 1e9 # Convert to mJ\n",
    "print(f\"Total Energy: {total_energy :.4f} mj, Area: {total_area :.2f} um^2\")\n",
    "\n",
    "answer( # DO NOT MODIFY\n",
    "    question='3.1.1',\n",
    "    subquestion='',\n",
    "    answer=total_energy<1.0,\n",
    "    required_type=bool,\n",
    ")\n",
    "answer( # DO NOT MODIFY\n",
    "    question='3.1.1',\n",
    "    subquestion='',\n",
    "    answer=total_energy<0.95,\n",
    "    required_type=bool,\n",
    ")\n",
    "answer( # DO NOT MODIFY\n",
    "    question='3.1.1',\n",
    "    subquestion='',\n",
    "    answer=total_energy<0.85,\n",
    "    required_type=bool,\n",
    ")\n",
    "answer( # DO NOT MODIFY\n",
    "    question='3.1.1',\n",
    "    subquestion='',\n",
    "    answer=total_energy<0.75,\n",
    "    required_type=bool,\n",
    ")\n",
    "answer( # DO NOT MODIFY\n",
    "    question='3.1.1',\n",
    "    subquestion='',\n",
    "    answer=total_energy<0.65,\n",
    "    required_type=bool,\n",
    ")\n",
    "answer( # DO NOT MODIFY\n",
    "    question='3.1.2',\n",
    "    subquestion='',\n",
    "    answer=total_area<20000,\n",
    "    required_type=bool,\n",
    ")\n",
    "answer( # DO NOT MODIFY\n",
    "    question='3.1.2',\n",
    "    subquestion='',\n",
    "    answer=total_area<18000,\n",
    "    required_type=bool,\n",
    ")\n",
    "answer( # DO NOT MODIFY\n",
    "    question='3.1.2',\n",
    "    subquestion='',\n",
    "    answer=total_area<16000,\n",
    "    required_type=bool,\n",
    ")\n",
    "answer( # DO NOT MODIFY\n",
    "    question='3.1.2',\n",
    "    subquestion='',\n",
    "    answer=total_area<14000,\n",
    "    required_type=bool,\n",
    ")\n",
    "answer( # DO NOT MODIFY\n",
    "    question='3.1.2',\n",
    "    subquestion='',\n",
    "    answer=total_area<12000,\n",
    "    required_type=bool,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
